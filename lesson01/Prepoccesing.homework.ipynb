{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##предварительная обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #матрицы\n",
    "import pandas as pd #датафреймы, таблицы\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Очень глубокие проймы</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Я недовольна заказом.Я вот одного не понимаю п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>заказала размер s на от 64,об 94,начнем с того...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Заказ я сделала в июле. С тех пор посылка отсл...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ужасное качество товара!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative\n",
       "1  Товар отдали другому человеку, я не получила п...  negative\n",
       "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
       "3  товар не пришел, продавец продлил защиту без м...  negative\n",
       "4      Кофточка голая синтетика, носить не возможно.  negative\n",
       "5                              Очень глубокие проймы  negative\n",
       "6  Я недовольна заказом.Я вот одного не понимаю п...  negative\n",
       "7  заказала размер s на от 64,об 94,начнем с того...  negative\n",
       "8  Заказ я сделала в июле. С тех пор посылка отсл...  negative\n",
       "9                           Ужасное качество товара!  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Чтение датасета с текстом\n",
    "df = pd.read_csv(\"reviews.csv\", encoding='UTF8', sep=\"\\t\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'товар не пришел, продавец продлил защиту без моего согласия. от продавца одни обещания'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    товар отдали другому человеку, я не получила п...\n",
       "2    ужасная синтетика! тонкая, ничего общего с пре...\n",
       "3    товар не пришел, продавец продлил защиту без м...\n",
       "4        кофточка голая синтетика, носить не возможно.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Нижний регистр. Например, Товар --> товар, УРА --> ура\n",
    "df['review']  = df['review'].str.lower()\n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдали другому человеку, получила посылк...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасная синтетика! тонкая, общего представленн...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар пришел, продавец продлил защиту моего со...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голая синтетика, носить возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative\n",
       "1  товар отдали другому человеку, получила посылк...  negative\n",
       "2  ужасная синтетика! тонкая, общего представленн...  negative\n",
       "3  товар пришел, продавец продлил защиту моего со...  negative\n",
       "4         кофточка голая синтетика, носить возможно.  negative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    товар отдали другому человеку, получила посылк...\n",
       "2    ужасная синтетика! тонкая, общего представленн...\n",
       "3    товар пришел, продавец продлил защиту моего со...\n",
       "4           кофточка голая синтетика, носить возможно.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление пунктуации\n",
    "df['review'] = df['review'].str.replace('[^\\w\\s]','')\n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `word` not found.\n"
     ]
    }
   ],
   "source": [
    "?word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2592\\1742576963.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i][0] = ''.join(symbol for symbol in df.iloc[i][0] if symbol not in exclude)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдали другому человеку, получила посылк...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасная синтетика! тонкая, общего представленн...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар пришел, продавец продлил защиту моего со...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голая синтетика, носить возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative\n",
       "1  товар отдали другому человеку, получила посылк...  negative\n",
       "2  ужасная синтетика! тонкая, общего представленн...  negative\n",
       "3  товар пришел, продавец продлил защиту моего со...  negative\n",
       "4         кофточка голая синтетика, носить возможно.  negative"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предыдущее удаление пунктуации почему-то не сработало, поэтому вот\n",
    "#к сожалению, это тоже перестало работать\n",
    "exclude = set(string.punctuation)\n",
    "for i in range(0,len(df)):\n",
    "    df.iloc[i][0] = ''.join(symbol for symbol in df.iloc[i][0] if symbol not in exclude)\n",
    "#s = ''.join(ch for ch in s if ch not in exclude)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный (горловина напер...\n",
       "1    товар отдали другому человеку, получила посылк...\n",
       "2    ужасная синтетика! тонкая, общего представленн...\n",
       "3    товар пришел, продавец продлил защиту моего со...\n",
       "4           кофточка голая синтетика, носить возможно.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление стоп-слов\n",
    "#Импорт стоп-слов из бибилиотеки nltk\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('russian'))\n",
    "# функция, удаляющая стопслова из текстов\n",
    "\n",
    "def stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "# Применим функцию удаления стоп-слов\n",
    "df[\"review\"] = df[\"review\"].apply(stopwords)\n",
    "df[\"review\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 80205),\n",
       " ('на', 53139),\n",
       " ('и', 42323),\n",
       " ('в', 32788),\n",
       " ('очень', 27788),\n",
       " ('но', 21844),\n",
       " ('размер', 19024),\n",
       " ('что', 14570),\n",
       " ('с', 13687),\n",
       " ('как', 13376)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление высокочастотных слов\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"review\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный горловина напере...\n",
       "1    товар отдали другому человеку я получила посыл...\n",
       "2    ужасная синтетика тонкая ничего общего предста...\n",
       "3    товар пришел продавец продлил защиту без моего...\n",
       "4             кофточка голая синтетика носить возможно\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ужаление часто встречающиеся слов в корпусе при помощи tf-idf\n",
    "# Удаление самых частотных слов\n",
    "freq = set([w for (w, wc) in cnt.most_common(10)])\n",
    "# функция удаления слов\n",
    "def freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not \n",
    "in freq])\n",
    "# применение функции\n",
    "df[\"review\"] = df[\"review\"].apply(freqwords)\n",
    "df[\"review\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный горловина напере...\n",
       "1    товар отдали другому человеку я получила посыл...\n",
       "2    ужасная синтетика тонкая ничего общего предста...\n",
       "3    товар пришел продавец продлил защиту без моего...\n",
       "4             кофточка голая синтетика носить возможно\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление низкочастотных слов\n",
    "freq = pd.Series(' '.join(df['review']).split()).value_counts()[-10:] # 10 rare words\n",
    "freq = list(freq.index)\n",
    "df['review'] = df['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление эмодзи\n",
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "#passing the emoji function to 'text_rare'\n",
    "df['review'] = df['review'].apply(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    качество плохое пошив ужасный горловина напере...\n",
       "1    товар отдали другому человеку я получила посыл...\n",
       "2    ужасная синтетика тонкая ничего общего предста...\n",
       "3    товар пришел продавец продлил защиту без моего...\n",
       "4             кофточка голая синтетика носить возможно\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление цифр\n",
    "df['review'] = df['review'].str.replace('\\d+', '') \n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление URL\n",
    "# Function for url's\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "# Examples\n",
    "text = \"This is my website, https://www.link.com\"\n",
    "remove_urls(text)\n",
    "#Passing the function to 'text_rare'\n",
    "df['review'] = df['review'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Это \n",
      " странца\n",
      " пример\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Удаление HTML-тегов\n",
    "from bs4 import BeautifulSoup\n",
    "#Function for removing html\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "# Examples\n",
    "text = \"\"\"<div>\n",
    "<h1> Это </h1>\n",
    "<p> странца</p>\n",
    "<a href=\"https://www.link.com/\"> пример</a>\n",
    "</div>\n",
    "\"\"\"\n",
    "print(html(text))\n",
    "# Passing the function to 'review'\n",
    "df['review'] = df['review'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[качество, плохое, пошив, ужасный, горловина, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[товар, отдали, другому, человеку, я, получила...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ужасная, синтетика, тонкая, ничего, общего, п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[товар, пришел, продавец, продлил, защиту, без...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[кофточка, голая, синтетика, носить, возможно]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  [качество, плохое, пошив, ужасный, горловина, ...\n",
       "1  [товар, отдали, другому, человеку, я, получила...\n",
       "2  [ужасная, синтетика, тонкая, ничего, общего, п...\n",
       "3  [товар, пришел, продавец, продлил, защиту, без...\n",
       "4     [кофточка, голая, синтетика, носить, возможно]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Токенизация\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "# Passing the function to 'text_rare' and store into'text_token'\n",
    "df['review'] = df['review'].apply(lambda x: tokenization(x.lower()))\n",
    "df[['review']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymorphy2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MorphAnalyzer \u001b[38;5;66;03m#вот тут тоже ничего не получилось\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize, regexp_tokenize\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_lemmas\u001b[39m(sent, pat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?u)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, morph\u001b[38;5;241m=\u001b[39mMorphAnalyzer()):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [morph\u001b[38;5;241m.\u001b[39mparse(tok)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnormal_form \n\u001b[0;32m      7\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m regexp_tokenize(sent, pat)]\n\u001b[0;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokenize_lemmas(x)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_type_orig \u001b[38;5;241m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_units(units)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m item[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(unit), \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bound_unit\u001b[39m(\u001b[38;5;28mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    247\u001b[0m     unit\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetargspec(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(args[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "#Можно выполнить при помощи NLTK. Заодно проведем лемматизацию\n",
    "from pymorphy2 import MorphAnalyzer #вот тут тоже ничего не получилось\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "\n",
    "def tokenize_lemmas(sent, pat=r\"(?u)\\b\\w\\w+\\b\", morph=MorphAnalyzer()):\n",
    "    return [morph.parse(tok)[0].normal_form \n",
    "            for tok in regexp_tokenize(sent, pat)]\n",
    "df[\"review\"] = df[\"review\"].map(lambda x: \" \".join(tokenize_lemmas(x)))\n",
    "df[['review']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохой пошив ужасный горловина напере...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>товар отдать другой человек получить посылка л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ужасный синтетик тонкий общий представить карт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар прийти продавец продлить защита мой согл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>кофточка голый синтетик носить возможно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_ready\n",
       "0  качество плохой пошив ужасный горловина напере...\n",
       "1  товар отдать другой человек получить посылка л...\n",
       "2  ужасный синтетик тонкий общий представить карт...\n",
       "3  товар прийти продавец продлить защита мой согл...\n",
       "4            кофточка голый синтетик носить возможно"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Исходя из цели автоматической обработки текста, выберем необходимые варианты предобработки текста. \n",
    "#Например, для классификации можно воспользоваться нижним регистром, удалением  пунктуации, ссылок, стоп-слов, \n",
    "#произвести лемматизацию и токенизацию\n",
    "##ИЛИ воспользоваться только удалением ссылок. Т.к. это актуальнее для НС, а выбор предобработки сделал для Машинного обученя\n",
    "df['text_ready']  = df['review'].str.lower()\n",
    "df['text_ready'] = df['text_ready'].str.replace('\\d+', '') \n",
    "df['text_ready'] = df['text_ready'].str.replace('[^\\w\\s]','')\n",
    "df[\"text_ready\"] = df[\"text_ready\"].apply(stopwords)\n",
    "df['text_ready'] = df['text_ready'].apply(emoji)\n",
    "df['text_ready'] = df['text_ready'].apply(remove_urls)\n",
    "df['text_ready'] = df['text_ready'].apply(html)\n",
    "df[\"text_ready\"] = df[\"text_ready\"].map(lambda x: \" \".join(tokenize_lemmas(x)))\n",
    "df[['text_ready']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Пример препобученной модели HuggingFace Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошая погода! Наконец-то тепло!\n"
     ]
    }
   ],
   "source": [
    "#txt = df.iloc[2,2]\n",
    "txt = \"Хорошая погода! Наконец-то тепло!\"\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predict(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
